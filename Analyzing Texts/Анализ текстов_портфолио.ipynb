{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2dd3095",
   "metadata": {},
   "source": [
    "# Анализ текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a70cd20",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис, чтобы пользователи могли редактировать и дополнять описания товаров, как в вики-сообществах. Магазину нужен инструмент, который будет определять токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. Заказчик предоставил набор данных с разметкой о токсичности правок.  Следует построить несколько разных моделей и рекомендовать ту, которая покажет наилучший результат. Задача - добиться метрики качества F1 не меньше 0.75.\n",
    "\n",
    "Совместно с заказчиком определили список моделей для исследования:\n",
    "\n",
    "- Логистическая регрессия\n",
    "- Случайный лес\n",
    "- CatBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87f20b",
   "metadata": {},
   "source": [
    "# 1. Загрузка и исследование данных \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f0c73e",
   "metadata": {},
   "source": [
    "Загрузим необходимые для работы библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e64960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#импорт библиотек \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8efdb420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0\n",
       "5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7           7  Your vandalism to the Matt Shirvington article...      0\n",
       "8           8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9           9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#импортируем данные\n",
    "data = pd.read_csv('toxic_comments.csv') \n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac021f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#удалим столбец-дубль индексов 'Unnamed: 0'\n",
    "data = data.drop(columns = ['Unnamed: 0'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a1ccc",
   "metadata": {},
   "source": [
    "Посмотрим на типы данных, количество строк и узнаем, есть ли пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4a906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c8ee1",
   "metadata": {},
   "source": [
    "Пропуски в данных отсутствуют."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd74fb",
   "metadata": {},
   "source": [
    "# 1.2.  Проверка на дисбаланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0dca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 16186 rows, 10.16%\n",
      "non_toxic: 143106 rows, 89.84%\n"
     ]
    }
   ],
   "source": [
    "toxic_len = data[data['toxic'] == 1].shape[0]\n",
    "toxic_non_len = data[data['toxic'] != 1].shape[0]\n",
    "\n",
    "print('toxic: {:d} rows, {:.2%}'.format(toxic_len, toxic_len / data.shape[0]))\n",
    "print('non_toxic: {:d} rows, {:.2%}'.format(toxic_non_len, toxic_non_len / data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b708fed0",
   "metadata": {},
   "source": [
    "Соотношение классов -  1:9. Необходимо учесть это в параметрах моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01a570",
   "metadata": {},
   "source": [
    "# 1.3 Нормализация и лемматизация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9a865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/anastasiabatmanova/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/anastasiabatmanova/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# создадим функцию для очистки и лемматизации текста\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def process_text(s):\n",
    "    s = s.lower()\n",
    "    words = [re.sub(r\"[^a-zA-Z]\", \"\", word) for word in word_tokenize(s)]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word != \"\"]\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5376a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#применим функцию для очистки  и лемматизации текста\n",
    "data['text'] = data['text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd812563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww he match this background colour i m seemi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i ca nt make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  daww he match this background colour i m seemi...      0\n",
       "2  hey man i m really not trying to edit war it s...      0\n",
       "3  more i ca nt make any real suggestion on impro...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b67f0a",
   "metadata": {},
   "source": [
    "Тексты готовы для превращения в признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789fa75",
   "metadata": {},
   "source": [
    "# 1.4. Подготовка массива признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3193dc",
   "metadata": {},
   "source": [
    "Теперь надо обработать текст, чтобы превратить наборы слов в признаки. Используем технологию TF-IDF.\n",
    "Также разобьем данные на выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86ca20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (119469,)\n",
      "y_train.shape (119469,)\n",
      "X_test.shape (39823,)\n",
      "y_test.shape (39823,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'],data['toxic'], \n",
    "                                                    test_size=0.25, random_state=12345)\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"y_test.shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e4ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anastasiabatmanova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#загрузим список стоп-слов\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk_stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b36814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим счётчик, указав в нём стоп-слова\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "train_features = count_tf_idf.fit_transform(X_train.values.astype('U'))\n",
    "test_features = count_tf_idf.transform(X_test.values.astype('U'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b911b",
   "metadata": {},
   "source": [
    "# 2.  Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06864c0",
   "metadata": {},
   "source": [
    "Обучим три разных модели:\n",
    "\n",
    "- Логистическая регрессия\n",
    "- Случайный лес\n",
    "- CatBoost\n",
    "\n",
    "Так как наша цель состоит в том, чтобы принципиально определить наилучшую модель, а массив данных получился большим, для сокращения времени подбор гиперпараматеров с помощью кросс-валидации проводить не будем. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab601af",
   "metadata": {},
   "source": [
    "# 2.1 Логистическая регрессия\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1769a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация логистической регрессии\n",
    "model_lr = LogisticRegression(solver='lbfgs', \n",
    "                              max_iter=1000, \n",
    "                              class_weight='balanced',\n",
    "                              random_state=12345, \n",
    "                              verbose=0)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3952bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, random_state=12345)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучаем модель логистической регрессии\n",
    "model_lr.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf484b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogistiсRegression F1 score - 0.7471127900701565\n"
     ]
    }
   ],
   "source": [
    "#проверяем предсказание на валидационной выборке \n",
    "predict = model_lr.predict(test_features)\n",
    "f1_lr = f1_score(y_test, predict)\n",
    "print('LogistiсRegression F1 score -', f1_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86f324",
   "metadata": {},
   "source": [
    "# 2.2. Случайный лес\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee1693e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=5, n_estimators=1000,\n",
       "                       random_state=12345)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(\n",
    "    n_estimators=1000, criterion='gini', max_depth=5, min_samples_split=2, min_samples_leaf=1, \n",
    "    min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "    random_state=12345, verbose=0, class_weight='balanced')\n",
    "model_rf.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74278c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor F1 score - 0.35177416966885455\n"
     ]
    }
   ],
   "source": [
    "predict = model_rf.predict(test_features)\n",
    "f1_rf = f1_score(y_test, predict)\n",
    "print('RandomForestRegressor F1 score -', f1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271dc86",
   "metadata": {},
   "source": [
    "# 2.3. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c1c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.079419\n",
      "0:\tlearn: 0.6606477\ttotal: 832ms\tremaining: 13m 50s\n",
      "100:\tlearn: 0.4132445\ttotal: 1m 5s\tremaining: 9m 41s\n",
      "200:\tlearn: 0.3599040\ttotal: 2m 7s\tremaining: 8m 27s\n",
      "300:\tlearn: 0.3274321\ttotal: 3m 9s\tremaining: 7m 19s\n",
      "400:\tlearn: 0.3052919\ttotal: 4m 13s\tremaining: 6m 18s\n",
      "500:\tlearn: 0.2885927\ttotal: 5m 22s\tremaining: 5m 20s\n",
      "600:\tlearn: 0.2744167\ttotal: 6m 26s\tremaining: 4m 16s\n",
      "700:\tlearn: 0.2630890\ttotal: 7m 23s\tremaining: 3m 9s\n",
      "800:\tlearn: 0.2533012\ttotal: 8m 32s\tremaining: 2m 7s\n",
      "900:\tlearn: 0.2446372\ttotal: 9m 32s\tremaining: 1m 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_cat = CatBoostClassifier(\n",
    "            n_estimators=1000, \n",
    "            class_weights=[1, 9],\n",
    "            max_depth=4, \n",
    "            verbose=100)\n",
    "model_cat.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc68101",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_cat.predict(test_features)\n",
    "f1_cat = f1_score(y_test, predict)\n",
    "print('CatBoostRegressor F1 score -', f1_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8414676",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe64bec",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "В ходе работы были сделаны следующие шаги:\n",
    "- обнаружен дисбаланс классов в соотношении 1:9. Токсичные комментарии составляют примерно одну десятую часть набора текстов.\n",
    "- проведена очистка и лемматизация текстов\n",
    "- создан набор векторов признаков по технологии TF-IDF - относительная встречаемость слов в корпусе текстов\n",
    "- обучены и проверены на тестовой выборке три модели: логистическая регрессия, случайный лес, CatBoost.\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Наилучший результат показала модель CatBoost -  при помощи этой модели удалось добиться F1= 0.752. \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
